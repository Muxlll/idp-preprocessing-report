
\chapter{Introduction}

Machine Learning and Computer Vision has gained much importance in the last years. It can be used in many application fields, such as smart plant monitoring. In this context, it can be used to simplify certain workflows. One example is the hail damage detection of sugar beets. 

The idea is to develop a system or application which automatically predicts the damage of plants. This has several advantages, for example less time has to be spent analyzing the fields and possible more accurate results can be achieved. 

More concrete, a mobile application was developed, which allows to take images of sugar beet plants. The fotos taken should then be preprocessed and sent to a backend server which analyzes the images and predicts the damage. 

In the context of this report, the preprocessing step of such a mobile application is presented. The general idea of the preprocessing step in this application is to standardize the image format of the fotos taken. This means that factors like the number of sugar beet plants, the angle in which the foto was taken and many more things are not often optimal for the model that is predicting the damage. In general, the images that we use for training are taken from directly above the plant in a 90 degrees angle. In the best case, the image only contains one plant which is directly in the center. To be therefore consistent with training images, the new pictures of the plants should ideally be in the same format with similar settings. Therefore, the preprocessing step helps to get better results by standardization of the images. \\

Object detection has gained much more importance in the last years. As an example, \cite{object_detection_history} present that the number of publications about "object detection" or "detecting objects" has increased from approximately 200 in 2005 to about 100 in 2017 and even nearly 1200 in 2018. They also present some state of the art algorithms for this task. Deep convolutional neural networks play an important role for them as feature extractor for the so called backbone part of a network. They call it the "engine" of a detector as a very important part. The authors name different concrete examples as state of the art object detection algorithms. Three of them are discussed in the following. There are different tradeoffs that influence the design of the network. \cite{discussion_engines} presents a discussion about different feature extractors for object detection algorithms.

Faster R-CNN (region-based convolutional neural networks) presented by \cite{faster_rcnn} is an improvement of Fast R-CNN (\cite{fast_rcnn}). The authors describe that the problem of other detectors is the region proposal of objects meaning that the location of bounding boxes is not fast enough by now. Therefore, they introduce a region proposal network which automatically locates objects. 

As another concrete example, \cite{rfcn} introduces R-FCN (Region-based fully convolutional networks). They call it an improvement of Fast and Faster R-CNN and improve the times of locating an object in an image. Almost all computation is made on the whole image by so called position-sensitive score maps.

A next example is single shot multibox detector (SSD) which is presented by \cite{ssd}. For this method, location proposals are not even necessary anymore. It is a single deep neural network which predicts scores and parameters of default bounding boxes of objects in an image at inference time. 

As fourth example, \cite{yolov1} introduces the first version of the so called YOLO network. It is used in this work and a more concrete description and evolution is provided in chapter 2. \\

These algorithms are used in many different application fields. This is also the case for agriculture. For example \cite{wheat_heads} applied an improved fifth version of the YOLO network to detect the heads of wheat plants. They use the data set provided by \cite{wheat_dataset}, to learn their network. This application and availability of the images with their labels shows the importance of this field.

Another example of object detection in agriculture is presented by \cite{terrain_example}. They use this technique to classify terrain using 3D lidar data. 

\cite{bale_detection} also presented one application of object detection in agriculture. Especially, they focus on one big problem of real world scenarios which is the lack of labeled data. They present a pipeline which consists of one object detection algorithm trained on a small amount of images, transfer learning and an optimized detector with the help of synthesized data.

Similar to our application case, also detected damage of sugar beet plants. The difference to our goal was to predict mechanical damages caused by harvesting the plants. The camera used was located directly inside the harvester machine. The author compared different architectures including YOLOv4 (\cite{yolov4}), region-based fully convolutional network (R-FCN) and faster regions with convolutional neural network features (Faster R-CNN). The results of their work show that YOLOv4 predicted the sugar beets with better accuracy and also faster than the other two methods. \\


All in all, there is a wide range of application cases of object detection in agriculture. For a broader overview, refer to \cite{applications_review}. The survey provides state of the art algorithms and techniques for object detection and tracking algorithms especially for unmanned aerial vehicles. 