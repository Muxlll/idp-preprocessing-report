\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand*\new@tpo@label[2]{}
\@nameuse{bbl@beforestart}
\catcode `"\active 
\abx@aux@refcontext{nyt/global//global/global}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\providecommand\BKM@entry[2]{}
\@writefile{toc}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\@writefile{lof}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\@writefile{lot}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\babel@aux{american}{}
\BKM@entry{id=1,dest={636861707465722A2E31},srcline={1}}{4162737472616374}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\nonumberline Abstract}{ii}{chapter*.1}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lol}{\defcounter {refsection}{0}\relax }\@writefile{lol}{\addvspace {10\p@ }}
\BKM@entry{id=2,dest={746F632E30},srcline={36}}{436F6E74656E7473}
\BKM@entry{id=3,dest={636861707465722E31},srcline={2}}{496E74726F64756374696F6E}
\abx@aux@cite{object_detection_history}
\abx@aux@segm{0}{0}{object_detection_history}
\abx@aux@cite{discussion_engines}
\abx@aux@segm{0}{0}{discussion_engines}
\abx@aux@cite{faster_rcnn}
\abx@aux@segm{0}{0}{faster_rcnn}
\abx@aux@cite{fast_rcnn}
\abx@aux@segm{0}{0}{fast_rcnn}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.1}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lol}{\defcounter {refsection}{0}\relax }\@writefile{lol}{\addvspace {10\p@ }}
\abx@aux@page{1}{1}
\abx@aux@page{2}{1}
\abx@aux@page{3}{1}
\abx@aux@cite{rfcn}
\abx@aux@segm{0}{0}{rfcn}
\abx@aux@cite{ssd}
\abx@aux@segm{0}{0}{ssd}
\abx@aux@cite{yolov1}
\abx@aux@segm{0}{0}{yolov1}
\abx@aux@cite{wheat_heads}
\abx@aux@segm{0}{0}{wheat_heads}
\abx@aux@cite{wheat_dataset}
\abx@aux@segm{0}{0}{wheat_dataset}
\abx@aux@cite{terrain_example}
\abx@aux@segm{0}{0}{terrain_example}
\abx@aux@cite{bale_detection}
\abx@aux@segm{0}{0}{bale_detection}
\abx@aux@cite{applications_review}
\abx@aux@segm{0}{0}{applications_review}
\abx@aux@page{4}{2}
\abx@aux@page{5}{2}
\abx@aux@page{6}{2}
\abx@aux@page{7}{2}
\abx@aux@page{8}{2}
\abx@aux@page{9}{2}
\abx@aux@page{10}{2}
\abx@aux@page{11}{2}
\abx@aux@page{12}{2}
\BKM@entry{id=4,dest={636861707465722E32},srcline={2}}{5468656F7265746963616C204261636B67726F756E64}
\abx@aux@cite{yolov1}
\abx@aux@segm{0}{0}{yolov1}
\abx@aux@cite{yolov2}
\abx@aux@segm{0}{0}{yolov2}
\abx@aux@cite{yolov3}
\abx@aux@segm{0}{0}{yolov3}
\abx@aux@cite{yolov4}
\abx@aux@segm{0}{0}{yolov4}
\abx@aux@cite{RCNN}
\abx@aux@segm{0}{0}{RCNN}
\BKM@entry{id=5,dest={73656374696F6E2E322E31},srcline={10}}{47656E6572616C20417263686974656374757265206F6620594F4C4F}
\abx@aux@cite{yolov1}
\abx@aux@segm{0}{0}{yolov1}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {2}Theoretical Background}{3}{chapter.2}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lol}{\defcounter {refsection}{0}\relax }\@writefile{lol}{\addvspace {10\p@ }}
\abx@aux@page{13}{3}
\abx@aux@page{14}{3}
\abx@aux@page{15}{3}
\abx@aux@page{16}{3}
\abx@aux@page{17}{3}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {2.1}General Architecture of YOLO}{3}{section.2.1}\protected@file@percent }
\abx@aux@page{18}{3}
\abx@aux@cite{yolov1}
\abx@aux@segm{0}{0}{yolov1}
\abx@aux@cite{yolov1}
\abx@aux@segm{0}{0}{yolov1}
\abx@aux@cite{yolov1}
\abx@aux@segm{0}{0}{yolov1}
\abx@aux@cite{yolov1}
\abx@aux@segm{0}{0}{yolov1}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces The model divides the image into $ S \times S $ grids. For each of them, $ B $ bounding boxes and $ C $ class probabilities are predicted. The overall result is a tensor of size $ S \times S \times (B*5 + C) $. Taken from \cite {yolov1}.\relax }}{4}{figure.caption.3}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:YOLO_idea}{{2.1}{4}{The model divides the image into $ S \times S $ grids. For each of them, $ B $ bounding boxes and $ C $ class probabilities are predicted. The overall result is a tensor of size $ S \times S \times (B*5 + C) $. Taken from \cite {yolov1}.\relax }{figure.caption.3}{}}
\BKM@entry{id=6,dest={73656374696F6E2E322E32},srcline={32}}{496E6372656D656E74616C20496D70726F76656D656E7473}
\abx@aux@cite{yolov1}
\abx@aux@segm{0}{0}{yolov1}
\abx@aux@cite{yolov2}
\abx@aux@segm{0}{0}{yolov2}
\abx@aux@cite{yolov3}
\abx@aux@segm{0}{0}{yolov3}
\abx@aux@cite{yolov4}
\abx@aux@segm{0}{0}{yolov4}
\abx@aux@cite{yolov5}
\abx@aux@segm{0}{0}{yolov5}
\abx@aux@cite{pytorch_hub_yolov5}
\abx@aux@segm{0}{0}{pytorch_hub_yolov5}
\abx@aux@cite{yolov2}
\abx@aux@segm{0}{0}{yolov2}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces The network consists of 24 convolutional and two fully connected layers. In this case, $ S = 7, B = 2 and C = 20 $, so a tensor of size $ 7 \times 7 \times 30 $ results. Taken from \cite {yolov1}.\relax }}{5}{figure.caption.4}\protected@file@percent }
\newlabel{fig:YOLO_network}{{2.2}{5}{The network consists of 24 convolutional and two fully connected layers. In this case, $ S = 7, B = 2 and C = 20 $, so a tensor of size $ 7 \times 7 \times 30 $ results. Taken from \cite {yolov1}.\relax }{figure.caption.4}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {2.2}Incremental Improvements}{5}{section.2.2}\protected@file@percent }
\abx@aux@page{23}{5}
\abx@aux@page{24}{5}
\abx@aux@page{25}{5}
\abx@aux@page{26}{5}
\abx@aux@page{27}{5}
\abx@aux@page{28}{5}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{\nonumberline YOLOv2}{5}{section*.5}\protected@file@percent }
\abx@aux@page{29}{5}
\abx@aux@cite{yolov3}
\abx@aux@segm{0}{0}{yolov3}
\abx@aux@cite{yolov3}
\abx@aux@segm{0}{0}{yolov3}
\abx@aux@cite{yolov3}
\abx@aux@segm{0}{0}{yolov3}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{\nonumberline YOLOv3}{6}{section*.6}\protected@file@percent }
\abx@aux@page{30}{6}
\abx@aux@cite{yolov4}
\abx@aux@segm{0}{0}{yolov4}
\abx@aux@cite{yolov4}
\abx@aux@segm{0}{0}{yolov4}
\abx@aux@cite{yolov4}
\abx@aux@segm{0}{0}{yolov4}
\abx@aux@cite{Wang_2020_CVPR_Workshops}
\abx@aux@segm{0}{0}{Wang_2020_CVPR_Workshops}
\abx@aux@cite{7005506}
\abx@aux@segm{0}{0}{7005506}
\abx@aux@cite{Liu_2018_CVPR}
\abx@aux@segm{0}{0}{Liu_2018_CVPR}
\abx@aux@cite{yolov3}
\abx@aux@segm{0}{0}{yolov3}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Darknet-53 consists of 53 convolutional layers. Taken from \cite {yolov3}.\relax }}{7}{figure.caption.7}\protected@file@percent }
\newlabel{fig:yolov3_architecture}{{2.3}{7}{Darknet-53 consists of 53 convolutional layers. Taken from \cite {yolov3}.\relax }{figure.caption.7}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{\nonumberline YOLOv4}{7}{section*.8}\protected@file@percent }
\abx@aux@page{35}{7}
\BKM@entry{id=7,dest={73656374696F6E2E322E33},srcline={79}}{43757272656E742041726368697465637475726520594F4C4F7635}
\abx@aux@cite{yolov5}
\abx@aux@segm{0}{0}{yolov5}
\abx@aux@cite{yolov5}
\abx@aux@segm{0}{0}{yolov5}
\abx@aux@cite{yolov5}
\abx@aux@segm{0}{0}{yolov5}
\abx@aux@cite{release_current}
\abx@aux@segm{0}{0}{release_current}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces The different parts of a detector. Input is given to the Backbone which forwards it to the Neck. The last part is the Dense Prediction. A Two-Stage-Detector differs from a One-Stage-Detector as it has an additional Sparse Prediction at the end. Taken from \cite {yolov4}.\relax }}{8}{figure.caption.9}\protected@file@percent }
\newlabel{fig:yolov4_architecture}{{2.4}{8}{The different parts of a detector. Input is given to the Backbone which forwards it to the Neck. The last part is the Dense Prediction. A Two-Stage-Detector differs from a One-Stage-Detector as it has an additional Sparse Prediction at the end. Taken from \cite {yolov4}.\relax }{figure.caption.9}{}}
\abx@aux@page{36}{8}
\abx@aux@page{37}{8}
\abx@aux@page{38}{8}
\abx@aux@page{39}{8}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {2.3}Current Architecture YOLOv5}{8}{section.2.3}\protected@file@percent }
\abx@aux@page{40}{8}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{\nonumberline Different Network Sizes}{8}{section*.10}\protected@file@percent }
\abx@aux@page{43}{8}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {2.1}{\ignorespaces Comparison of the different network sizes regarding inference speed, number of parameters and mean average precision with IOU threshold of 0.5. Values taken from \cite {yolov5}.\relax }}{9}{table.caption.11}\protected@file@percent }
\newlabel{tab:network_sizes}{{2.1}{9}{Comparison of the different network sizes regarding inference speed, number of parameters and mean average precision with IOU threshold of 0.5. Values taken from \cite {yolov5}.\relax }{table.caption.11}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{\nonumberline Additional Features}{9}{section*.12}\protected@file@percent }
\BKM@entry{id=8,dest={636861707465722E33},srcline={2}}{4D6574686F646F6C6F6779}
\BKM@entry{id=9,dest={73656374696F6E2E332E31},srcline={8}}{44617461736574}
\abx@aux@cite{deng2009imagenet}
\abx@aux@segm{0}{0}{deng2009imagenet}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {3}Methodology}{10}{chapter.3}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lol}{\defcounter {refsection}{0}\relax }\@writefile{lol}{\addvspace {10\p@ }}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {3.1}Dataset}{10}{section.3.1}\protected@file@percent }
\abx@aux@page{44}{10}
\newlabel{fig:type_1}{{3.1a}{11}{Image type (1). Shows multiple small plants and the boundaries can be seen perfectly.\relax }{figure.caption.13}{}}
\newlabel{sub@fig:type_1}{{a}{11}{Image type (1). Shows multiple small plants and the boundaries can be seen perfectly.\relax }{figure.caption.13}{}}
\newlabel{fig:type_2}{{3.1b}{11}{Image type (2). Shows one larger plant, boundaries are overlapping with neighboring plants.\relax }{figure.caption.13}{}}
\newlabel{sub@fig:type_2}{{b}{11}{Image type (2). Shows one larger plant, boundaries are overlapping with neighboring plants.\relax }{figure.caption.13}{}}
\newlabel{fig:type_3}{{3.1c}{11}{Image type (3). Shows many larger plants. The boundaries of single sugar beets can hardly be seen.\relax }{figure.caption.13}{}}
\newlabel{sub@fig:type_3}{{c}{11}{Image type (3). Shows many larger plants. The boundaries of single sugar beets can hardly be seen.\relax }{figure.caption.13}{}}
\newlabel{fig:type_4}{{3.1d}{11}{Image type (4). Shows plants from a different angle than $ 90° $.\relax }{figure.caption.13}{}}
\newlabel{sub@fig:type_4}{{d}{11}{Image type (4). Shows plants from a different angle than $ 90° $.\relax }{figure.caption.13}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Example images of types (1), (2), (3) and (4).\relax }}{11}{figure.caption.13}\protected@file@percent }
\newlabel{fig:image_types}{{3.1}{11}{Example images of types (1), (2), (3) and (4).\relax }{figure.caption.13}{}}
\abx@aux@cite{labelimg}
\abx@aux@segm{0}{0}{labelimg}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Overview over the data set with the available images. (1) and (2) are given by TUM. Images of type (3) are screenshots from drone videos and (4) from partner.\relax }}{12}{figure.caption.14}\protected@file@percent }
\newlabel{fig:bar_chart}{{3.2}{12}{Overview over the data set with the available images. (1) and (2) are given by TUM. Images of type (3) are screenshots from drone videos and (4) from partner.\relax }{figure.caption.14}{}}
\BKM@entry{id=10,dest={73656374696F6E2E332E32},srcline={94}}{547261696E696E67}
\abx@aux@cite{COCO}
\abx@aux@segm{0}{0}{COCO}
\abx@aux@cite{yolov5}
\abx@aux@segm{0}{0}{yolov5}
\abx@aux@page{45}{13}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Labeling with labelImg\relax }}{13}{figure.caption.15}\protected@file@percent }
\newlabel{fig:labeling}{{3.3}{13}{Labeling with labelImg\relax }{figure.caption.15}{}}
\abx@aux@cite{yolov5}
\abx@aux@segm{0}{0}{yolov5}
\abx@aux@cite{yolov5}
\abx@aux@segm{0}{0}{yolov5}
\BKM@entry{id=11,dest={73656374696F6E2E332E33},srcline={113}}{496E666572656E636520616E64204576616C756174696F6E}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {3.2}Training}{14}{section.3.2}\protected@file@percent }
\abx@aux@page{46}{14}
\abx@aux@page{47}{14}
\abx@aux@cite{yolov5}
\abx@aux@segm{0}{0}{yolov5}
\abx@aux@cite{metrics_survey}
\abx@aux@segm{0}{0}{metrics_survey}
\BKM@entry{id=12,dest={73656374696F6E2E332E34},srcline={130}}{4D6F62696C6520446574656374696F6E}
\abx@aux@cite{pytorch_mobile}
\abx@aux@segm{0}{0}{pytorch_mobile}
\abx@aux@cite{survey_machine_learning_mobile}
\abx@aux@segm{0}{0}{survey_machine_learning_mobile}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {3.3}Inference and Evaluation}{15}{section.3.3}\protected@file@percent }
\abx@aux@page{50}{15}
\abx@aux@page{51}{15}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {3.4}Mobile Detection}{16}{section.3.4}\protected@file@percent }
\abx@aux@page{52}{16}
\abx@aux@page{53}{16}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Augmentation types, taken from \cite {yolov5}\relax }}{17}{figure.caption.16}\protected@file@percent }
\newlabel{fig:augmentation}{{3.4}{17}{Augmentation types, taken from \cite {yolov5}\relax }{figure.caption.16}{}}
\BKM@entry{id=13,dest={636861707465722E34},srcline={2}}{526573756C7473}
\BKM@entry{id=14,dest={73656374696F6E2E342E31},srcline={6}}{4C61726765204E6574776F726B}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {4}Results}{18}{chapter.4}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lol}{\defcounter {refsection}{0}\relax }\@writefile{lol}{\addvspace {10\p@ }}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4.1}Large Network}{18}{section.4.1}\protected@file@percent }
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces Values for data augmentation\relax }}{18}{table.caption.17}\protected@file@percent }
\newlabel{tab:augmentation_exp1}{{4.1}{18}{Values for data augmentation\relax }{table.caption.17}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Examples of detected images.\relax }}{19}{figure.caption.18}\protected@file@percent }
\newlabel{fig:results_experiment_1}{{4.1}{19}{Examples of detected images.\relax }{figure.caption.18}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Examples of other plants also detected as sugar beets.\relax }}{19}{figure.caption.19}\protected@file@percent }
\newlabel{fig:false_positives}{{4.2}{19}{Examples of other plants also detected as sugar beets.\relax }{figure.caption.19}{}}
\newlabel{fig:AUC_1}{{4.3a}{20}{P-R-curve for the first experiment. With mainly automatically labeled images, an average precision of only 0.741 can be achieved.\relax }{figure.caption.20}{}}
\newlabel{sub@fig:AUC_1}{{a}{20}{P-R-curve for the first experiment. With mainly automatically labeled images, an average precision of only 0.741 can be achieved.\relax }{figure.caption.20}{}}
\newlabel{fig:AUC_2}{{4.3b}{20}{P-R-curve for the second experiment. Now, the AUC has increased to 0.818 by adding manually labeled images. \relax }{figure.caption.20}{}}
\newlabel{sub@fig:AUC_2}{{b}{20}{P-R-curve for the second experiment. Now, the AUC has increased to 0.818 by adding manually labeled images. \relax }{figure.caption.20}{}}
\newlabel{fig:AUC_3}{{4.3c}{20}{P-R-curve of third experiment. Now, higher data augmentation is used, leading to higher AUC of 0.839.\relax }{figure.caption.20}{}}
\newlabel{sub@fig:AUC_3}{{c}{20}{P-R-curve of third experiment. Now, higher data augmentation is used, leading to higher AUC of 0.839.\relax }{figure.caption.20}{}}
\newlabel{fig:AUC_4}{{4.3d}{20}{P-R-curve of fourth experiment. Now, the training was done with two classes (also other\_plant). The resulting AUC is 0.865.\relax }{figure.caption.20}{}}
\newlabel{sub@fig:AUC_4}{{d}{20}{P-R-curve of fourth experiment. Now, the training was done with two classes (also other\_plant). The resulting AUC is 0.865.\relax }{figure.caption.20}{}}
\newlabel{fig:AUC_5}{{4.3e}{20}{P-R-curve of last experiment. With only one class and higher data augmentation, an average precision of 0.872 can be achieved.\relax }{figure.caption.20}{}}
\newlabel{sub@fig:AUC_5}{{e}{20}{P-R-curve of last experiment. With only one class and higher data augmentation, an average precision of 0.872 can be achieved.\relax }{figure.caption.20}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces Comparison of testing P-R-curves of the different training experiments.\relax }}{20}{figure.caption.20}\protected@file@percent }
\newlabel{fig:AUC_comparison}{{4.3}{20}{Comparison of testing P-R-curves of the different training experiments.\relax }{figure.caption.20}{}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {4.2}{\ignorespaces Values for higher data augmentation\relax }}{21}{table.caption.21}\protected@file@percent }
\newlabel{tab:high_augmentation}{{4.2}{21}{Values for higher data augmentation\relax }{table.caption.21}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces Direct comparison of the average precision of the different training experiments. At first, the AUC increases fast. A saturation can be seen at the last experiments.\relax }}{22}{figure.caption.22}\protected@file@percent }
\newlabel{fig:direct_comparison}{{4.4}{22}{Direct comparison of the average precision of the different training experiments. At first, the AUC increases fast. A saturation can be seen at the last experiments.\relax }{figure.caption.22}{}}
\BKM@entry{id=15,dest={73656374696F6E2E342E32},srcline={166}}{536D616C6C20616E64204D656469756D204E6574776F726B}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4.2}Small and Medium Network}{23}{section.4.2}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces Predictions of sugar beets in screenshots of drone videos. Now, single plants are detected with high accuracy of bounding boxes. \relax }}{24}{figure.caption.23}\protected@file@percent }
\newlabel{fig:current_predictions}{{4.5}{24}{Predictions of sugar beets in screenshots of drone videos. Now, single plants are detected with high accuracy of bounding boxes. \relax }{figure.caption.23}{}}
\BKM@entry{id=16,dest={73656374696F6E2E342E33},srcline={193}}{436F6D70617269736F6E20616E642044697363757373696F6E}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces Comparison of small and medium sized model. Left one (small model) has AUC of 0.806 and right one (medium) AUC of 0.805.\relax }}{25}{figure.caption.24}\protected@file@percent }
\newlabel{fig:comparison_small_medium}{{4.6}{25}{Comparison of small and medium sized model. Left one (small model) has AUC of 0.806 and right one (medium) AUC of 0.805.\relax }{figure.caption.24}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4.7}{\ignorespaces Result of the better trained small model. Now, the average precision is 0.858.\relax }}{25}{figure.caption.25}\protected@file@percent }
\newlabel{fig:result_small_one}{{4.7}{25}{Result of the better trained small model. Now, the average precision is 0.858.\relax }{figure.caption.25}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4.3}Comparison and Discussion}{25}{section.4.3}\protected@file@percent }
\newlabel{fig:result_1}{{4.8a}{28}{Example of an image with only one plant. The image is already similar to the standardized format.\relax }{figure.caption.26}{}}
\newlabel{sub@fig:result_1}{{a}{28}{Example of an image with only one plant. The image is already similar to the standardized format.\relax }{figure.caption.26}{}}
\newlabel{fig:result_2}{{4.8b}{28}{Example of many small plants. The model is able to predict the boundaries very well because of nearly no overlap between the sugar beets.\relax }{figure.caption.26}{}}
\newlabel{sub@fig:result_2}{{b}{28}{Example of many small plants. The model is able to predict the boundaries very well because of nearly no overlap between the sugar beets.\relax }{figure.caption.26}{}}
\newlabel{fig:result_3}{{4.8c}{28}{Example of an image of plants with high damage. The picture was not taken optimally (angle, not centered on one plant). The model detects one plant at the top of the image.\relax }{figure.caption.26}{}}
\newlabel{sub@fig:result_3}{{c}{28}{Example of an image of plants with high damage. The picture was not taken optimally (angle, not centered on one plant). The model detects one plant at the top of the image.\relax }{figure.caption.26}{}}
\newlabel{fig:result_4}{{4.8d}{28}{Example of many larger plants. The model detects 5 sugar beet plants with relatively low confidence because the boundaries can not be seen very easily.\relax }{figure.caption.26}{}}
\newlabel{sub@fig:result_4}{{d}{28}{Example of many larger plants. The model detects 5 sugar beet plants with relatively low confidence because the boundaries can not be seen very easily.\relax }{figure.caption.26}{}}
\newlabel{fig:result_5}{{4.8e}{28}{Example of many larger plants. The model detects 2 sugar beet plants. The upper one with higher confidence because the boundaries are clearer there.\relax }{figure.caption.26}{}}
\newlabel{sub@fig:result_5}{{e}{28}{Example of many larger plants. The model detects 2 sugar beet plants. The upper one with higher confidence because the boundaries are clearer there.\relax }{figure.caption.26}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4.8}{\ignorespaces Results of the object detection algorithm. Different scenarios are tested.\relax }}{28}{figure.caption.26}\protected@file@percent }
\newlabel{fig:final_results}{{4.8}{28}{Results of the object detection algorithm. Different scenarios are tested.\relax }{figure.caption.26}{}}
\BKM@entry{id=17,dest={636861707465722E35},srcline={2}}{436F6E636C7573696F6E20616E64204F75746C6F6F6B}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {5}Conclusion and Outlook}{29}{chapter.5}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lol}{\defcounter {refsection}{0}\relax }\@writefile{lol}{\addvspace {10\p@ }}
\BKM@entry{id=18,dest={636861707465722A2E3237},srcline={54}}{4269626C696F677261706879}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\nonumberline Bibliography}{30}{chapter*.27}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lol}{\defcounter {refsection}{0}\relax }\@writefile{lol}{\addvspace {10\p@ }}
\abx@aux@page{54}{30}
\abx@aux@page{55}{30}
\abx@aux@page{56}{30}
\abx@aux@page{57}{30}
\abx@aux@page{58}{30}
\abx@aux@page{59}{30}
\abx@aux@page{60}{30}
\abx@aux@page{61}{30}
\abx@aux@page{62}{30}
\abx@aux@page{63}{30}
\abx@aux@page{64}{30}
\abx@aux@page{65}{31}
\abx@aux@page{66}{31}
\abx@aux@page{67}{31}
\abx@aux@page{68}{31}
\abx@aux@page{69}{31}
\abx@aux@page{70}{31}
\abx@aux@page{71}{31}
\abx@aux@page{72}{31}
\abx@aux@page{73}{31}
\abx@aux@page{74}{31}
\abx@aux@page{75}{31}
\abx@aux@page{76}{31}
\abx@aux@page{77}{31}
\abx@aux@page{78}{31}
\abx@aux@page{79}{31}
\abx@aux@refcontextdefaultsdone
\abx@aux@defaultrefcontext{0}{yolov4}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{rfcn}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{survey_machine_learning_mobile}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{wheat_dataset}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{deng2009imagenet}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{fast_rcnn}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{RCNN}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{wheat_heads}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{7005506}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{discussion_engines}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{yolov5}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{pytorch_hub_yolov5}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{release_current}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{terrain_example}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{labelimg}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{COCO}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{Liu_2018_CVPR}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{ssd}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{metrics_survey}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{pytorch_mobile}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{yolov1}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{yolov2}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{yolov3}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{faster_rcnn}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{Wang_2020_CVPR_Workshops}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{applications_review}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{bale_detection}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{object_detection_history}{nyt/global//global/global}
\abx@aux@page{80}{32}
\abx@aux@page{81}{32}
\global\@namedef{scr@dte@chapter@lastmaxnumwidth}{9.85492pt}
\global\@namedef{scr@dte@section@lastmaxnumwidth}{18.0674pt}
